{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lazaros/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # data visualization library  \n",
    "import statistics as stats # https://docs.python.org/3/library/statistics.html#statistics.fmean\n",
    "#import scipy.stats as spstats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Validation & Normalization methods ###\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, RepeatedStratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "### ML models ###\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier # C1 loss: log_loss => LogisticRegression with SGD\n",
    "from sklearn.linear_model import Perceptron # C2\n",
    "from sklearn.svm import SVC # C3\n",
    "from sklearn.svm import LinearSVC # C4\n",
    "from sklearn.tree import DecisionTreeClassifier # C5\n",
    "from sklearn.ensemble import RandomForestClassifier # C6\n",
    "from sklearn.neural_network import MLPClassifier # C7\n",
    "\n",
    "### Metrics ###\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, make_scorer\n",
    "from imblearn.metrics import geometric_mean_score # https://imbalanced-learn.org/stable/references/generated/imblearn.metrics.geometric_mean_score.html\n",
    "import time\n",
    "import timeit # https://stackoverflow.com/questions/17579357/time-time-vs-timeit-timeit\n",
    "\n",
    "### Pipeline ###\n",
    "from sklearn.pipeline import make_pipeline , Pipeline # https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "### Analysis ###\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, RFE, RFECV , mutual_info_classif\n",
    "\n",
    "### Custom Modules ###\n",
    "from functions.data_types import optimize_dtypes\n",
    "from functions.dataframe_actions import df_info, df_clean, show_value_counts, fill_missing_values\n",
    "from functions.ml_training import train_classifiers, train_classifiers_tuned, train_evaluate_single\n",
    "from functions.dimensionality_reduction import apply_pca, plot_variance\n",
    "\n",
    "### Other configurations ###\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# #import warnings library\n",
    "# import warnings\n",
    "# # ignore all warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(working_memory=1024*20) \n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering, FeatureAgglomeration\n",
    "from sklearn.decomposition import PCA, SparsePCA, KernelPCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read .csv files from another directory\n",
    "data_location = \"../Data/\" # \"/<path>\"\n",
    "\n",
    "df_train = pd.read_csv(data_location + \"train_filled_mapped.csv\")\n",
    "df_train = optimize_dtypes(df_train)\n",
    "# df_train.head()\n",
    "\n",
    "df_test = pd.read_csv(data_location + \"test_filled_mapped.csv\")\n",
    "df_test = optimize_dtypes(df_test)\n",
    "\n",
    "\n",
    "# Separate target variable from feature variables\n",
    "X_train = df_train.drop('HadHeartAttack', axis=1, inplace=False)  # Features\n",
    "y_train = df_train['HadHeartAttack']\n",
    "\n",
    "# Separate target variable from feature variables\n",
    "X_test = df_test.drop('HadHeartAttack', axis=1, inplace=False)  # Features\n",
    "y_test = df_test['HadHeartAttack']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dtypes = X_train.dtypes\n",
    "\n",
    "X_train_scaled = (X_train - X_train.min(axis=0)) / (X_train.max(axis=0)-X_train.min(axis=0))              # min max scale\n",
    "# X_train_scaled = (X_train - X_train.mean())/X_train.std() # If we use StandardScaler, the feature names will be lost, so we do it mannually.\n",
    "\n",
    "# x_scaled.hist(figsize=(16, 20), bins=30, edgecolor=\"black\") # plot to show features after scaling\n",
    "# plt.subplots_adjust()\n",
    "\n",
    "# Cast back to original data types\n",
    "for column, dtype in original_dtypes.items():\n",
    "    X_train_scaled[column] = X_train_scaled[column].astype(dtype)\n",
    "\n",
    "\n",
    "original_dtypes = X_test.dtypes\n",
    "\n",
    "# Apply Min-Max scaling based on training set statistics\n",
    "X_test_scaled = (X_test - X_train.min(axis=0)) / (X_train.max(axis=0) - X_train.min(axis=0))\n",
    "\n",
    "# Cast back to original data types\n",
    "for column, dtype in original_dtypes.items():\n",
    "    X_test_scaled[column] = X_test_scaled[column].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=15, svd_solver='full', random_state=13).fit(X_train_scaled)\n",
    "X_pca_train = pca.transform(X_train_scaled)\n",
    "X_pca_test = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.942713</td>\n",
       "      <td>0.538385</td>\n",
       "      <td>0.475259</td>\n",
       "      <td>0.082238</td>\n",
       "      <td>0.140214</td>\n",
       "      <td>0.8366</td>\n",
       "      <td>58.77455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     classifier  accuracy  balanced_accuracy  precision    recall  f1_score  \\\n",
       "0  RandomForest  0.942713           0.538385   0.475259  0.082238  0.140214   \n",
       "\n",
       "   roc_auc  fit_time  \n",
       "0   0.8366  58.77455  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', n_jobs=-1, class_weight='balanced', random_state=13)\n",
    "metrics_rf = train_evaluate_single(rf, X_pca_train, y_train, X_pca_test, y_test, classifier_name=\"RandomForest\")\n",
    "\n",
    "# Store metrics in a DataFrame\n",
    "metrics_df_rf = pd.DataFrame([metrics_rf])\n",
    "metrics_df_rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC(kernel = 'rbf', gamma='scale', cache_size=10000, class_weight='balanced', random_state=13)\n",
    "metrics_svc=train_evaluate_single(svc, X_pca_train, y_train, X_pca_test, y_test, classifier_name=\"LinearSVC\")\n",
    "\n",
    "# Store metrics in a DataFrame\n",
    "metrics_df_svc = pd.DataFrame([metrics_svc])\n",
    "metrics_df_svc\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
