{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lazaros/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # data visualization library  \n",
    "import statistics as stats # https://docs.python.org/3/library/statistics.html#statistics.fmean\n",
    "#import scipy.stats as spstats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### Validation & Normalization methods ###\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold, RepeatedStratifiedKFold, train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
    "\n",
    "### ML models ###\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier # C1 loss: log_loss => LogisticRegression with SGD\n",
    "from sklearn.linear_model import Perceptron # C2\n",
    "from sklearn.svm import NuSVC # C3\n",
    "from sklearn.svm import LinearSVC # C4\n",
    "from sklearn.tree import DecisionTreeClassifier # C5\n",
    "from sklearn.ensemble import RandomForestClassifier # C6\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "### Metrics ###\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, make_scorer\n",
    "from imblearn.metrics import geometric_mean_score # https://imbalanced-learn.org/stable/references/generated/imblearn.metrics.geometric_mean_score.html\n",
    "import time\n",
    "import timeit # https://stackoverflow.com/questions/17579357/time-time-vs-timeit-timeit\n",
    "\n",
    "### Pipeline ###\n",
    "from sklearn.pipeline import make_pipeline , Pipeline # https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "### Analysis ###\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, RFE, RFECV , mutual_info_classif\n",
    "\n",
    "### Custom Modules ###\n",
    "from functions.data_types import optimize_dtypes\n",
    "from functions.dataframe_actions import df_info, df_clean, show_value_counts, fill_missing_values\n",
    "from functions.ml_training import train_classifiers, train_classifiers_tuned, train_evaluate_single\n",
    "from functions.dimensionality_reduction import apply_pca, plot_variance\n",
    "\n",
    "### Other configurations ###\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "# #import warnings library\n",
    "# import warnings\n",
    "# # ignore all warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(working_memory=1024*20) \n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering, FeatureAgglomeration\n",
    "from sklearn.decomposition import PCA, SparsePCA, KernelPCA, TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to read .csv files from another directory\n",
    "data_location = \"../Data/\" # \"/<path>\"\n",
    "\n",
    "df_train = pd.read_csv(data_location + \"train_oversampled_smote.csv\")\n",
    "df_train = optimize_dtypes(df_train)\n",
    "# df_train.head()\n",
    "\n",
    "df_test = pd.read_csv(data_location + \"test_filled_mapped.csv\")\n",
    "df_test = optimize_dtypes(df_test)\n",
    "\n",
    "\n",
    "# Separate target variable from feature variables\n",
    "X_train = df_train.drop('HadHeartAttack', axis=1, inplace=False)  # Features\n",
    "y_train = df_train['HadHeartAttack']\n",
    "\n",
    "# Separate target variable from feature variables\n",
    "X_test = df_test.drop('HadHeartAttack', axis=1, inplace=False)  # Features\n",
    "y_test = df_test['HadHeartAttack']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dtypes = X_train.dtypes\n",
    "\n",
    "X_train_scaled = (X_train - X_train.min(axis=0)) / (X_train.max(axis=0)-X_train.min(axis=0))              # min max scale\n",
    "# X_train_scaled = (X_train - X_train.mean())/X_train.std() # If we use StandardScaler, the feature names will be lost, so we do it mannually.\n",
    "\n",
    "# x_scaled.hist(figsize=(16, 20), bins=30, edgecolor=\"black\") # plot to show features after scaling\n",
    "# plt.subplots_adjust()\n",
    "\n",
    "# Cast back to original data types\n",
    "for column, dtype in original_dtypes.items():\n",
    "    X_train_scaled[column] = X_train_scaled[column].astype(dtype)\n",
    "\n",
    "\n",
    "original_dtypes = X_test.dtypes\n",
    "\n",
    "# Apply Min-Max scaling based on training set statistics\n",
    "X_test_scaled = (X_test - X_train.min(axis=0)) / (X_train.max(axis=0) - X_train.min(axis=0))\n",
    "\n",
    "# Cast back to original data types\n",
    "for column, dtype in original_dtypes.items():\n",
    "    X_test_scaled[column] = X_test_scaled[column].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define multiple metrics\n",
    "# scoring = {'Balanced Accuracy': make_scorer(balanced_accuracy_score),\n",
    "#            'F1-score': make_scorer(f1_score, average='weighted'),\n",
    "#            'G-Mean score': make_scorer(geometric_mean_score, average='weighted')\n",
    "#           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=18, svd_solver='full', random_state=13).fit(X_train_scaled)\n",
    "X_pca_train = pca.transform(X_train_scaled)\n",
    "X_pca_test = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.830954</td>\n",
       "      <td>0.719512</td>\n",
       "      <td>0.187689</td>\n",
       "      <td>0.593787</td>\n",
       "      <td>0.285222</td>\n",
       "      <td>0.814538</td>\n",
       "      <td>9.5148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy  balanced_accuracy  precision    recall  f1_score  \\\n",
       "0        XGB  0.830954           0.719512   0.187689  0.593787  0.285222   \n",
       "\n",
       "    roc_auc  fit_time  \n",
       "0  0.814538    9.5148  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(booster='gbtree', validate_parameters=True, subsample=0.6 , random_state=13)\n",
    "metrics_xgb = train_evaluate_single(xgb, X_pca_train, y_train, X_pca_test, y_test, classifier_name=\"XGB\")\n",
    "\n",
    "# Store metrics in a DataFrame\n",
    "metrics_df_xgb = pd.DataFrame([metrics_xgb])\n",
    "metrics_df_xgb\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 333567, number of negative: 333567\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.121325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4590\n",
      "[LightGBM] [Info] Number of data points in the train set: 667134, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.822268</td>\n",
       "      <td>0.726884</td>\n",
       "      <td>0.183893</td>\n",
       "      <td>0.619275</td>\n",
       "      <td>0.283578</td>\n",
       "      <td>0.82332</td>\n",
       "      <td>13.880126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy  balanced_accuracy  precision    recall  f1_score  \\\n",
       "0       LGBM  0.822268           0.726884   0.183893  0.619275  0.283578   \n",
       "\n",
       "   roc_auc   fit_time  \n",
       "0  0.82332  13.880126  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm = LGBMClassifier( boosting_type='gbdt', objective='binary', subsample=0.6, random_state=13)\n",
    "metrics_lgbm = train_evaluate_single(lgbm, X_pca_train, y_train, X_pca_test, y_test, classifier_name=\"LGBM\")\n",
    "\n",
    "# Store metrics in a DataFrame\n",
    "metrics_df_lgbm = pd.DataFrame([metrics_lgbm])\n",
    "metrics_df_lgbm\n",
    "\n",
    "# https://xgboost.readthedocs.io/en/latest/parameter.html#learning-task-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.885799</td>\n",
       "      <td>0.678785</td>\n",
       "      <td>0.23421</td>\n",
       "      <td>0.445241</td>\n",
       "      <td>0.306953</td>\n",
       "      <td>0.829059</td>\n",
       "      <td>177.650139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy  balanced_accuracy  precision    recall  f1_score  \\\n",
       "0         RF  0.885799           0.678785    0.23421  0.445241  0.306953   \n",
       "\n",
       "    roc_auc    fit_time  \n",
       "0  0.829059  177.650139  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', n_jobs=-1, class_weight='balanced', random_state=13)\n",
    "metrics_rf = train_evaluate_single(rf, X_pca_train, y_train, X_pca_test, y_test, classifier_name=\"RF\")\n",
    "\n",
    "# Store metrics in a DataFrame\n",
    "metrics_df_rf = pd.DataFrame([metrics_rf])\n",
    "metrics_df_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.812349</td>\n",
       "      <td>0.688877</td>\n",
       "      <td>0.161507</td>\n",
       "      <td>0.549582</td>\n",
       "      <td>0.249649</td>\n",
       "      <td>0.761197</td>\n",
       "      <td>0.045656</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy  balanced_accuracy  precision    recall  f1_score  \\\n",
       "0        kNN  0.812349           0.688877   0.161507  0.549582  0.249649   \n",
       "\n",
       "    roc_auc  fit_time  \n",
       "0  0.761197  0.045656  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=-1)\n",
    "metrics_knn = train_evaluate_single(knn, X_pca_train, y_train, X_pca_test, y_test, classifier_name=\"kNN\")\n",
    "\n",
    "# Store metrics in a DataFrame\n",
    "metrics_df_knn = pd.DataFrame([metrics_knn])\n",
    "metrics_df_knn\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.772219</td>\n",
       "      <td>0.761638</td>\n",
       "      <td>0.166247</td>\n",
       "      <td>0.749701</td>\n",
       "      <td>0.272146</td>\n",
       "      <td>0.840593</td>\n",
       "      <td>0.99938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy  balanced_accuracy  precision    recall  f1_score  \\\n",
       "0        QDA  0.772219           0.761638   0.166247  0.749701  0.272146   \n",
       "\n",
       "    roc_auc  fit_time  \n",
       "0  0.840593   0.99938  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qda = QuadraticDiscriminantAnalysis(priors=None, reg_param=0.7, store_covariance=False, tol=0.0001)\n",
    "metrics_qda = train_evaluate_single(qda, X_pca_train, y_train, X_pca_test, y_test, classifier_name=\"QDA\")\n",
    "\n",
    "# Store metrics in a DataFrame\n",
    "metrics_df_qda = pd.DataFrame([metrics_qda])\n",
    "metrics_df_qda\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.825989</td>\n",
       "      <td>0.724085</td>\n",
       "      <td>0.185608</td>\n",
       "      <td>0.60912</td>\n",
       "      <td>0.284518</td>\n",
       "      <td>0.820218</td>\n",
       "      <td>161.614115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy  balanced_accuracy  precision   recall  f1_score  \\\n",
       "0        MLP  0.825989           0.724085   0.185608  0.60912  0.284518   \n",
       "\n",
       "    roc_auc    fit_time  \n",
       "0  0.820218  161.614115  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam', alpha=0.0001, batch_size='auto', learning_rate_init=0.001, max_iter=1000, shuffle=True, random_state=13, tol=0.0001, verbose=False, warm_start=False, early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=20)\n",
    "metrics_mlp = train_evaluate_single(mlp, X_pca_train, y_train, X_pca_test, y_test, classifier_name=\"MLP\")\n",
    "\n",
    "# Store metrics in a DataFrame\n",
    "metrics_df_mlp = pd.DataFrame([metrics_mlp])\n",
    "metrics_df_mlp\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis.html#sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.831</td>\n",
       "      <td>0.720</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.815</td>\n",
       "      <td>9.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBM</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.823</td>\n",
       "      <td>13.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.829</td>\n",
       "      <td>177.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kNN</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.272</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.186</td>\n",
       "      <td>0.609</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.820</td>\n",
       "      <td>161.614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  classifier  accuracy  balanced_accuracy  precision  recall  f1_score  \\\n",
       "0        XGB     0.831              0.720      0.188   0.594     0.285   \n",
       "0       LGBM     0.822              0.727      0.184   0.619     0.284   \n",
       "0         RF     0.886              0.679      0.234   0.445     0.307   \n",
       "0        kNN     0.812              0.689      0.162   0.550     0.250   \n",
       "0        QDA     0.772              0.762      0.166   0.750     0.272   \n",
       "0        MLP     0.826              0.724      0.186   0.609     0.285   \n",
       "\n",
       "   roc_auc  fit_time  \n",
       "0    0.815     9.515  \n",
       "0    0.823    13.880  \n",
       "0    0.829   177.650  \n",
       "0    0.761     0.046  \n",
       "0    0.841     0.999  \n",
       "0    0.820   161.614  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_smote_results = pd.concat([metrics_df_xgb, metrics_df_lgbm, metrics_df_rf, metrics_df_knn, metrics_df_qda, metrics_df_mlp])\n",
    "pca_smote_results = pca_smote_results.round(3)\n",
    "pca_smote_results.to_csv('../Data/results_pca_smote.csv', index=False)\n",
    "pca_smote_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - Borderline SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - KMeans SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA - Adasyn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
